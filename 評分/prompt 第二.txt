我現在正在實作一個衛教練習網頁的後端的評分系統
這是一個大腸鏡衛教系統 使用者(學員)要根據系統設定的Agent(病人)進行衛教
我們要設計一個系統對學員的衛教內容進行評分
但由於本地LLM的性能限制 所以每一項檢查項目都要獨立出來使用低參數LLM進行評分
我這邊預計使用的是gemma3:1b

然後搜尋方法是要先透過將評分標準做成向量資料庫，使用學員輸入去和範例答案進行相似度搜索前N個相似度最高的項目出來做評分
根據項目的不同也有不同的處理方式

這裡是我的全部檢查項目 但是有幾項項目還有細項
細項的說明如下:
每個子項目後會有個別之分數，依據衛教過程中所達成該項子項目數的比例，乘以該子項目的分數(例如:子項目”適切發問及引導以獲得正確且足夠的訊息”的分數為3分，臨床評核情境中共有4個”適切發問及引導以獲得正確且足夠的訊息”評核點，學員最後只完成2個，則該子項目的分數為(2/4)*3=1.5

項目:適切發問及引導以獲得正確且足夠的訊息 
細項:是否引導病人進到衛教對話、是否確認病人檢查型態、是否進行病人不知道檢查型態的引導對話、是否確認病人檢查時間

項目:說明藥物使用時機及方式
細項:是否正確說明第一包清腸劑泡製方法及服用方式、是否正確說明第二包清腸劑泡製方法及服用方式

項目:說明水分補充方式及清腸理想狀態
細項:是否正確說明水分補充方式、是否正確說明清腸理想狀態


我現在在這個評分系統上遇到了問題
由於目前的實作方式是只取得 最近三筆的使用者輸入 所以會出現LLM不知道上下文導致評分錯誤的情形 我想先把role(patinet)的回答加入到prompt中 看能不能減少這個評分誤判問題