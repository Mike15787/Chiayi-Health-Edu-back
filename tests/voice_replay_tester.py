# tests/voice_replay_tester.py
import sys
import os
import asyncio
import logging
import uuid
import re
from datetime import datetime
import whisper
import torch

# --- æ–°å¢éŸ³è¨Šè™•ç†å¥—ä»¶ ---
import soundfile as sf
import librosa
import noisereduce as nr
from pydub import AudioSegment
from pydub.silence import split_on_silence

# --- 1. ç’°å¢ƒè¨­å®š (å¿…é ˆåœ¨ import databases å‰è¨­å®š) ---
# å¼·åˆ¶è¨­å®šç‚ºçœŸäººæ¸¬è©¦ç’°å¢ƒï¼Œä»¥è®€å– human_test.db
os.environ["APP_ENV"] = "human"

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from databases import (
    init_database,
    SessionLocal,
    ChatLog,
    SessionUserMap,
    PrecomputedSessionAnswer,
    SessionInteractionLog,
    Scores,
    AgentSettings,
)
from module_manager import ModuleManager
from scoring_service_manager import ScoringServiceManager

# è¨­å®š Log
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger("VoiceReplayTester")

# å…¨åŸŸè®Šæ•¸
module_manager = ModuleManager()
scoring_service_manager = ScoringServiceManager()
whisper_model = None  # å»¶é²è¼‰å…¥

# æŒ‡å®šéŸ³æª”å­˜æ”¾ç›®éŒ„ (ç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„)
AUDIO_DIR = os.path.join(
    os.path.dirname(os.path.dirname(os.path.abspath(__file__))), "audio"
)

# æŒ‡å®šæš«å­˜è™•ç†å¾Œçš„éŸ³æª”ç›®éŒ„
TEMP_AUDIO_DIR = os.path.join(AUDIO_DIR, "processed_temp")
os.makedirs(TEMP_AUDIO_DIR, exist_ok=True)

def preprocess_audio(input_path: str) -> str:
    """
    éŸ³è¨Šå‰è™•ç†ï¼š
    1. é™å™ª (Noise Reduction)
    2. æ¶ˆé™¤éœéŸ³ (Silence Removal)
    å›å‚³è™•ç†å¾Œçš„æš«å­˜æª”æ¡ˆè·¯å¾‘ã€‚
    """
    try:
        # --- 1. é™å™ªè™•ç† (ä½¿ç”¨ noisereduce) ---
        # ä½¿ç”¨ librosa è®€å– (è½‰ç‚º float32 array, sr=å–æ¨£ç‡)
        data, rate = librosa.load(input_path, sr=None)

        # å‡è¨­éŸ³æª”å‰ 0.5 ç§’æ˜¯èƒŒæ™¯å™ªéŸ³ (è‹¥æ˜¯å°è©±å¾ˆæ»¿ï¼Œå¯æ”¹ç”¨ stationary=True)
        # prop_decrease=0.8 è¡¨ç¤ºé™ä½ 80% çš„å™ªéŸ³ï¼Œé¿å…äººè²å¤±çœŸ
        reduced_noise_data = nr.reduce_noise(
            y=data, sr=rate, prop_decrease=0.8, stationary=True
        )

        # æš«å­˜é™å™ªå¾Œçš„æª”æ¡ˆ
        temp_denoised_path = os.path.join(
            TEMP_AUDIO_DIR, f"denoised_{os.path.basename(input_path)}"
        )
        sf.write(temp_denoised_path, reduced_noise_data, rate)

        # --- 2. æ¶ˆé™¤éœéŸ³ (ä½¿ç”¨ pydub) ---
        # è®€å–å‰›å‰›é™å™ªå¾Œçš„æª”æ¡ˆ
        sound = AudioSegment.from_file(temp_denoised_path)

        # split_on_silence åƒæ•¸èªªæ˜:
        # min_silence_len: éœéŸ³è¶…éå¤šå°‘æ¯«ç§’å°±åˆ‡æ–· (700ms)
        # silence_thresh: ä½æ–¼å¤šå°‘åˆ†è²è¦–ç‚ºéœéŸ³ (æ¯”å¹³å‡éŸ³é‡ä½ 16dB)
        # keep_silence: åˆ‡æ–·å¾Œä¿ç•™å¤šå°‘æ¯«ç§’çš„éœéŸ³ï¼Œè®“èªå¥é€£æ¥æ¯”è¼ƒè‡ªç„¶ (200ms)
        dBFS = sound.dBFS
        chunks = split_on_silence(
            sound, min_silence_len=700, silence_thresh=dBFS - 16, keep_silence=200
        )

        if not chunks:
            # å¦‚æœåˆ‡å®Œæ²’æ±è¥¿(å…¨éƒ½æ˜¯éœéŸ³)ï¼Œå›å‚³ None
            logger.warning(
                f"éŸ³æª” {os.path.basename(input_path)} ç¶“è™•ç†å¾Œåˆ¤å®šç‚ºå…¨éœéŸ³ã€‚"
            )
            return None

        # å°‡åˆ‡é–‹çš„ééœéŸ³ç‰‡æ®µé‡æ–°æ¥èµ·ä¾†
        processed_sound = sum(chunks)

        # å¦‚æœè™•ç†å¾Œå¤ªçŸ­ (å°æ–¼ 0.5 ç§’)ï¼Œé€šå¸¸æ˜¯é›œè¨Šï¼Œç›´æ¥ä¸Ÿæ£„
        if len(processed_sound) < 500:
            logger.warning(
                f"éŸ³æª” {os.path.basename(input_path)} è™•ç†å¾ŒéçŸ­ (<0.5s)ï¼Œè¦–ç‚ºç„¡æ•ˆã€‚"
            )
            return None

        # åŒ¯å‡ºæœ€çµ‚æª”æ¡ˆ
        final_path = os.path.join(
            TEMP_AUDIO_DIR, f"clean_{os.path.basename(input_path)}"
        )
        processed_sound.export(final_path, format="wav")

        # æ¸…ç†ä¸­é–“æª”æ¡ˆ
        if os.path.exists(temp_denoised_path):
            os.remove(temp_denoised_path)

        return final_path

    except Exception as e:
        logger.error(f"éŸ³è¨Šå‰è™•ç†å¤±æ•—: {e}")
        # å¦‚æœè™•ç†å¤±æ•—ï¼Œå›å‚³åŸå§‹è·¯å¾‘å˜—è©¦è¾¨è­˜
        return input_path


def clean_repetitive_text(text: str) -> str:
    """æ¸…æ´—é‡è¤‡å­—å…ƒ"""
    if not text:
        return ""
    text = re.sub(r"(.)\1{4,}", r"\1", text)
    text = re.sub(r"(.{2})\1{3,}", r"\1", text)
    return text


def load_whisper_model():
    """è¼‰å…¥ Whisper æ¨¡å‹ (ä½¿ç”¨ GPU è‹¥å¯ç”¨)"""
    global whisper_model
    if whisper_model is None:
        logger.info("æ­£åœ¨è¼‰å…¥ Whisper æ¨¡å‹ (å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“)...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        # å»ºè­°ä½¿ç”¨ 'base' æˆ– 'small'ï¼Œè‹¥ VRAM è¶³å¤ å¯ç”¨ 'medium' æ•ˆæœæ›´å¥½
        whisper_model = whisper.load_model("small", device=device)
        logger.info(f"Whisper æ¨¡å‹è¼‰å…¥å®Œæˆ (Device: {device})")
    return whisper_model


def optimized_transcribe(audio_path: str) -> str:
    """
    å„ªåŒ–ç‰ˆè½‰éŒ„ Ver 3ï¼šå‰è™•ç† -> Whisper -> å¾Œè™•ç† -> èªé€Ÿæª¢æ ¸ (Sanity Check)
    """
    if not os.path.exists(audio_path):
        return "[éŸ³æª”éºå¤±]"

    # --- æ­¥é©Ÿ A: éŸ³è¨Šå‰è™•ç† ---
    clean_audio_path = preprocess_audio(audio_path)

    if clean_audio_path is None:
        return "[ç„¡æ•ˆèªéŸ³]"

    target_path = clean_audio_path

    # --- æ­¥é©Ÿ B: è¨ˆç®—éŸ³æª”é•·åº¦ (ç”¨æ–¼èªé€Ÿæª¢æ ¸) ---
    try:
        # å–å¾—éŸ³æª”ç§’æ•¸
        y, sr = librosa.load(target_path, sr=None)
        duration_sec = librosa.get_duration(y=y, sr=sr)
    except:
        duration_sec = 0.0

    # --- æ­¥é©Ÿ C: Whisper è½‰éŒ„ ---
    model = load_whisper_model()
    initial_prompt = (
        "ä»¥ä¸‹æ˜¯é—œæ–¼å¤§è…¸é¡è¡›æ•™çš„é†«å­¸å°è©±ã€‚é—œéµå­—åŒ…å«:å¤§è…¸é¡æª¢æŸ¥ã€æ¸…è…¸åŠ‘ã€æ¸…è…¸è—¥ã€ä¿å¯æ·¨ã€"
        "ä½æ¸£é£²é£Ÿã€ç„¡æ¸£æµè³ªé£²é£Ÿã€ç€‰è—¥ã€éº»é†‰ã€å£æœç€‰è—¥éŒ åŠ‘ã€æ¨‚å¯èˆ’ã€‚"
    )

    try:
        result = model.transcribe(
            target_path,
            language="zh",
            fp16=False,
            initial_prompt=initial_prompt,
            temperature=0.2,
            beam_size=5,
            best_of=5,
            condition_on_previous_text=False,
            compression_ratio_threshold=1.8,  # [å†èª¿ä½] æ›´åš´æ ¼ï¼Œç¨å¾®æœ‰é‡è¤‡å°±é‡è©¦
            logprob_threshold=-1.0,
            no_speech_threshold=0.6,
        )

        raw_text = result["text"].strip()

        # --- æ­¥é©Ÿ D: æ–‡å­—å¾Œè™•ç† ---
        cleaned_text = clean_repetitive_text(raw_text)

        # æ¸…ç†æš«å­˜æª”
        if target_path != audio_path and os.path.exists(target_path):
            os.remove(target_path)

        # --- æ­¥é©Ÿ E: èªé€Ÿåˆç†æ€§æª¢æ ¸ (Sanity Check) ---
        # å¦‚æœéŸ³æª”å¾ˆçŸ­ (< 1ç§’) å»ç”¢å‡ºå¾ˆå¤šå­— (> 10å­—)ï¼Œé€™çµ•å°æ˜¯å¹»è¦º
        if duration_sec > 0:
            chars_per_sec = len(cleaned_text) / duration_sec

            # æ­£å¸¸èªªè©±ç´„ 3-5 å­—/ç§’ï¼Œå¿«å˜´é ‚å¤š 8-9 å­—/ç§’ã€‚
            # å¦‚æœè¶…é 15 å­—/ç§’ï¼Œæˆ–æ˜¯éŸ³æª”å°æ–¼ 1 ç§’å»è¶…é 8 å€‹å­—ï¼Œåˆ¤å®šç‚ºå¹»è¦ºã€‚
            if chars_per_sec > 12.0:
                logger.warning(
                    f"åµæ¸¬åˆ°èªé€Ÿç•°å¸¸ (å¹»è¦º): {duration_sec:.2f}ç§’ ç”¢å‡º {len(cleaned_text)}å­— -> '{cleaned_text}'"
                )
                return "[èƒŒæ™¯é›œéŸ³]"

            if duration_sec < 1.0 and len(cleaned_text) > 8:
                logger.warning(
                    f"çŸ­éŸ³æª”å¹»è¦º: {duration_sec:.2f}ç§’ ç”¢å‡º '{cleaned_text}'"
                )
                return "[èƒŒæ™¯é›œéŸ³]"

        # æœ€å¾Œæª¢æŸ¥ï¼šå¦‚æœæ¸…æ´—å¾Œé•·åº¦å¤§å¹…ç¸®æ¸› (ä»£è¡¨åŸæœ¬å¤§éƒ¨åˆ†éƒ½æ˜¯é‡è¤‡)ï¼Œä¸”å‰©ä¸‹å…§å®¹æ¥µçŸ­
        if len(raw_text) > 20 and len(cleaned_text) < 5:
            return "[å¹»è¦ºéæ¿¾]"

        return cleaned_text

    except Exception as e:
        logger.error(f"è½‰éŒ„å¤±æ•—: {e}")
        return "[è½‰éŒ„å¤±æ•—]"


def get_next_replay_session_id(db, original_session_id: str) -> str:
    """ç”¢ç”Ÿå¸¶æœ‰ _replay å¾Œç¶´çš„ Session ID"""
    base_id = original_session_id.split("_replay")[0]
    pattern = f"{base_id}_replay%"
    similar_sessions = (
        db.query(SessionUserMap.session_id)
        .filter(SessionUserMap.session_id.like(pattern))
        .all()
    )

    count = len(similar_sessions) + 1
    return f"{base_id}_replay_{count}"


async def run_voice_replay_test(target_session_ids: list):
    """
    ä¸»æµç¨‹ï¼šè®€å–èˆŠ Session -> é‡è½‰éŒ„éŸ³æª” -> å»ºç«‹æ–° Session -> è©•åˆ†
    """
    db = SessionLocal()

    try:
        for original_session_id in target_session_ids:
            logger.info(f"\n{'='*60}")
            logger.info(f"é–‹å§‹è™•ç† Session: {original_session_id}")
            logger.info(f"{'='*60}")

            # 1. å–å¾—åŸå§‹ Session è³‡æ–™
            src_map = (
                db.query(SessionUserMap)
                .filter(SessionUserMap.session_id == original_session_id)
                .first()
            )
            if not src_map:
                logger.error(f"âŒ è³‡æ–™åº«æ‰¾ä¸åˆ° Session: {original_session_id}")
                continue

            # 2. å»ºç«‹æ–°çš„ Replay Session ID
            new_session_id = get_next_replay_session_id(db, original_session_id)
            logger.info(f"å»ºç«‹æ–°çš„æ¸¬è©¦ Session ID: {new_session_id}")

            # 3. è¤‡è£½ SessionUserMap
            new_map = SessionUserMap(
                session_id=new_session_id,
                username=f"{src_map.username}_Replay",
                agent_code=src_map.agent_code,
                module_id=src_map.module_id,
                created_at=datetime.now(),
                is_completed=False,
            )
            db.add(new_map)

            # 4. è¤‡è£½ PrecomputedSessionAnswer (ç­”æ¡ˆå·)
            src_pre = (
                db.query(PrecomputedSessionAnswer)
                .filter(PrecomputedSessionAnswer.session_id == original_session_id)
                .first()
            )
            if src_pre:
                new_pre = PrecomputedSessionAnswer(
                    session_id=new_session_id,
                    module_id=src_pre.module_id,
                    exam_day=src_pre.exam_day,
                    prev_1d=src_pre.prev_1d,
                    prev_2d=src_pre.prev_2d,
                    prev_3d=src_pre.prev_3d,
                    second_dose_time=src_pre.second_dose_time,
                    npo_start_time=src_pre.npo_start_time,
                    actual_check_type=src_pre.actual_check_type,
                )
                db.add(new_pre)

            # 5. è¤‡è£½ UI äº’å‹•ç´€éŒ„ (ä¿ç•™ UI æ“ä½œåˆ†æ•¸)
            src_interact = (
                db.query(SessionInteractionLog)
                .filter(SessionInteractionLog.session_id == original_session_id)
                .first()
            )
            if src_interact:
                new_interact = SessionInteractionLog(
                    session_id=new_session_id,
                    module_id=src_interact.module_id,
                    viewed_alltimes_ci=src_interact.viewed_alltimes_ci,
                    viewed_chiachi_med=src_interact.viewed_chiachi_med,
                    viewed_med_allergy=src_interact.viewed_med_allergy,
                    viewed_disease_diag=src_interact.viewed_disease_diag,
                    viewed_cloud_med=src_interact.viewed_cloud_med,
                )
                db.add(new_interact)

            db.commit()

            # 6. è™•ç†å°è©±ç´€éŒ„ (é‡è½‰éŒ„èˆ‡é‡å»º)
            original_logs = (
                db.query(ChatLog)
                .filter(ChatLog.session_id == original_session_id)
                .order_by(ChatLog.time)
                .all()
            )

            chat_history_list = []  # ç”¨æ–¼è©•åˆ†çš„æ ¼å¼

            print(f"\n--- å°è©±é‡è£½èˆ‡è½‰éŒ„å°æ¯” ---")
            print(f"{'è§’è‰²':<6} | {'åŸå§‹æ–‡å­— (Old)':<30} | {'é‡æ–°è½‰éŒ„ (New STT)'}")
            print("-" * 80)

            for log in original_logs:
                new_text = log.text  # é è¨­ä½¿ç”¨èˆŠæ–‡å­— (é‡å° AI å›æ‡‰)

                # å¦‚æœæ˜¯ User ä¸”æœ‰éŸ³æª”ï¼Œé€²è¡Œé‡è½‰éŒ„
                if log.role == "user" and log.audio_filename:
                    full_audio_path = os.path.join(AUDIO_DIR, log.audio_filename)
                    transcribed_text = optimized_transcribe(full_audio_path)

                    # æ¯”å°é¡¯ç¤º
                    print(f"{'User':<6} | {log.text[:28]:<30} | {transcribed_text}")
                    new_text = transcribed_text
                elif log.role == "user":
                    print(f"{'User':<6} | {log.text[:28]:<30} | [ç„¡éŸ³æª”]")
                else:
                    # AI çš„è©±ç›´æ¥ä¿ç•™
                    pass

                new_chat_log = ChatLog(
                    session_id=new_session_id,
                    user_id=log.user_id,
                    agent_code=log.agent_code,
                    module_id=log.module_id,
                    role=log.role,
                    text=new_text,
                    audio_filename=log.audio_filename,  # ä¿ç•™éŸ³æª”é€£çµ
                    time=log.time,  # ä¿ç•™ç›¸å°æ™‚é–“é †åº
                )

                # [ä¿®æ”¹ 2] åŠ å…¥ä¸¦ Flushï¼Œé€™æ¨£ new_chat_log.id æ‰æœƒæœ‰å€¼
                db.add(new_chat_log)
                db.flush()  # <--- é—œéµï¼é€™æœƒç”¢ç”Ÿ idï¼Œä½†é‚„æ²’ commit

                # æº–å‚™çµ¦è©•åˆ†ç”¨çš„ snippet
                chat_history_list.append({"role": log.role, "message": new_text})

                # æ¨¡æ“¬å³æ™‚è©•åˆ† (é›–ç„¶æ˜¯å›æ”¾ï¼Œä½†ç‚ºäº†ç¢ºä¿é‚è¼¯ä¸€è‡´ï¼Œæˆ‘å€‘æ‰¹æ¬¡é€å…¥ User çš„è©±)
                if log.role == "user":
                    snippet = chat_history_list[-5:]  # å–æœ€è¿‘5å¥
                    await scoring_service_manager.process_user_inputs_for_scoring(
                        new_session_id,
                        src_map.module_id,
                        snippet,
                        db,
                        chat_log_id=new_chat_log.id,
                    )

            db.commit()

            # 7. è¨ˆç®—æœ€çµ‚åˆ†æ•¸
            logger.info("æ­£åœ¨è¨ˆç®—æœ€çµ‚åˆ†æ•¸...")
            final_scores = await scoring_service_manager.calculate_final_scores(
                new_session_id, src_map.module_id, db
            )

            # 8. å¯«å…¥åˆ†æ•¸èˆ‡å®Œæˆç‹€æ…‹
            new_score_record = Scores(
                session_id=new_session_id,
                module_id=src_map.module_id,
                **{
                    k: v
                    for k, v in final_scores.items()
                    if k in Scores.__table__.columns.keys()
                },
            )
            db.merge(new_score_record)

            # æ›´æ–° Session Map
            updated_map = (
                db.query(SessionUserMap)
                .filter(SessionUserMap.session_id == new_session_id)
                .first()
            )
            updated_map.score = final_scores.get("total_score", "0")
            updated_map.is_completed = True

            db.commit()

            # 9. æ¯”è¼ƒæ–°èˆŠåˆ†æ•¸
            old_score_record = (
                db.query(Scores)
                .filter(Scores.session_id == original_session_id)
                .first()
            )
            old_total = old_score_record.total_score if old_score_record else "N/A"
            new_total = final_scores.get("total_score", "N/A")

            print(f"\nğŸ“Š åˆ†æ•¸æ¯”è¼ƒ (Agent: {src_map.agent_code})")
            print(f"   åŸå§‹åˆ†æ•¸: {old_total}")
            print(f"   é‡æ¸¬åˆ†æ•¸: {new_total}")
            print(f"   è©³ç´°çµæœè«‹è¦‹è³‡æ–™åº« Session: {new_session_id}")

    except Exception as e:
        logger.error(f"æ¸¬è©¦éç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}", exc_info=True)
    finally:
        db.close()


if __name__ == "__main__":
    # ç›®æ¨™ Session IDs
    target_sessions = [
        "session_1769949647951_b0cin8d6b",
        "session_1769948170673_m4nq4emf1",
    ]

    print(f"ğŸš€ å•Ÿå‹•èªéŸ³å›æ”¾æ¸¬è©¦ (Voice Replay Tester)")
    print(f"ğŸ“‚ è³‡æ–™åº«ä¾†æº: human_test.db")
    print(f"ğŸ¯ ç›®æ¨™ Session æ•¸é‡: {len(target_sessions)}")

    # åˆå§‹åŒ–è³‡æ–™åº«é€£æ¥
    init_database()

    asyncio.run(run_voice_replay_test(target_sessions))
